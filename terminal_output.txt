D:\anaconda3\envs\porf\python.exe C:\Users\krameri120\Desktop\porf\surface.py 
D:\anaconda3\envs\porf\lib\site-packages\kornia\feature\lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
2.4.0+cu121
--- STAGE 1: Feature Extraction ---
Executing: colmap feature_extractor --database_path porf_data/dtu\scan24\database.db --image_path porf_data/dtu\scan24\images --ImageReader.single_camera 1
Features extracted successfully.

--- STAGE 2: Feature Matching ---
Executing: colmap exhaustive_matcher --database_path porf_data/dtu\scan24\database.db
Features matched successfully.

--- STAGE 3: Sparse Reconstruction with GloMAP ---
Executing: glomap mapper --database_path porf_data/dtu\scan24\database.db --image_path porf_data/dtu\scan24\images --output_path porf_data/dtu\scan24\sparse
Sparse map created successfully with GloMAP.

Finished running GloMAP, see porf_data/dtu\scan24\glomap_output.txt for logs.
Don't need to run GLOMAP
Post-colmap
Cameras 5
000000.png
000001.png
000002.png
000003.png
000004.png
000005.png
000006.png
000007.png
000008.png
000009.png
000010.png
000011.png
000012.png
000013.png
000014.png
000015.png
000016.png
000017.png
000018.png
000019.png
000020.png
000021.png
000022.png
000023.png
000024.png
000025.png
000026.png
000027.png
000028.png
000029.png
000030.png
000031.png
000032.png
000033.png
000034.png
000035.png
000036.png
000037.png
000038.png
000039.png
000040.png
000041.png
000042.png
000043.png
000044.png
000045.png
000046.png
000047.png
000048.png
Images # 49
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48]
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
(3, 5, 49)
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Points (12795, 3) Visibility (12795, 49)
test [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48]
Done with imgs2poses
Filtered point cloud saved to porf_data/dtu\scan24\sparse_points_interest.ply
49
Process done!
Opening database: porf_data\dtu\scan24\database.db
Clean old matches in porf_data/dtu\scan24\colmap_matches
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
D:\anaconda3\envs\porf\lib\site-packages\numpy\lib\npyio.py:696: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  val = np.asanyarray(val)
D:\anaconda3\envs\porf\lib\site-packages\torch\__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\torch\csrc\tensor\python_tensor.cpp:434.)
  _C._set_default_tensor_type(t)
<module 'torch.__config__' from 'D:\\anaconda3\\envs\\porf\\lib\\site-packages\\torch\\__config__.py'>
Hello Wooden
general {
    base_exp_dir = ./exp_dtu/scan24/dtu_sift_porf
    recording = [
        ./,
        ./models
    ]
}

dataset {
    data_dir = ./porf_data/dtu/scan24/
    render_cameras_name = cameras_colmap.npz
    object_cameras_name = cameras_colmap.npz
    train_resolution_level = 1
    match_folder = colmap_matches
    mask_folder = mask
}

train {
    learning_rate = 1e-3
    learning_rate_alpha = 0.05

    pose_learning_rate = 1e-3

    pose_end_iter = 50000
    pose_val_freq = 50

    use_porf = True
    scale = 1e-2 
    inlier_threshold = 20
    num_pairs = 20

    batch_size = 512
    validate_resolution_level = 4
    warm_up_end = 500
    anneal_end = 5000
    use_white_bkgd = False

    save_freq = 50000
    val_freq = 5000
    val_mesh_freq = 5000
    report_freq = 1000
    
    # loss weights
    igr_weight = 0.1
    color_loss_weight = 1.0
    epipolar_loss_weight = 0.1
}

model {
    sdf_network {
        d_out = 257
        d_in = 3
        d_hidden = 256
        n_layers = 8
        skip_in = [4]
        multires = 6
        bias = 0.5
        scale = 1.0
        geometric_init = True
        weight_norm = True
    }

    variance_network {
        init_val = 0.3
    }

    render_network {
        d_feature = 256
        mode = idr
        d_in = 9
        d_out = 3
        d_hidden = 256
        n_layers = 4
        weight_norm = True
        multires_view = 4
        squeeze_out = True
    }

    neus_renderer {
        n_samples = 64
        n_importance = 64
        n_outside = 32
        up_sample_steps = 4     # 1 for simple coarse-to-fine sampling
        perturb = 1.0
    }
}

Load data: Begin from ./porf_data/dtu/scan24/
['./porf_data/dtu/scan24/image/000000.png', './porf_data/dtu/scan24/image/000001.png', './porf_data/dtu/scan24/image/000002.png', './porf_data/dtu/scan24/image/000003.png', './porf_data/dtu/scan24/image/000004.png', './porf_data/dtu/scan24/image/000005.png', './porf_data/dtu/scan24/image/000006.png', './porf_data/dtu/scan24/image/000007.png', './porf_data/dtu/scan24/image/000008.png', './porf_data/dtu/scan24/image/000009.png', './porf_data/dtu/scan24/image/000010.png', './porf_data/dtu/scan24/image/000011.png', './porf_data/dtu/scan24/image/000012.png', './porf_data/dtu/scan24/image/000013.png', './porf_data/dtu/scan24/image/000014.png', './porf_data/dtu/scan24/image/000015.png', './porf_data/dtu/scan24/image/000016.png', './porf_data/dtu/scan24/image/000017.png', './porf_data/dtu/scan24/image/000018.png', './porf_data/dtu/scan24/image/000019.png', './porf_data/dtu/scan24/image/000020.png', './porf_data/dtu/scan24/image/000021.png', './porf_data/dtu/scan24/image/000022.png', './porf_data/dtu/scan24/image/000023.png', './porf_data/dtu/scan24/image/000024.png', './porf_data/dtu/scan24/image/000025.png', './porf_data/dtu/scan24/image/000026.png', './porf_data/dtu/scan24/image/000027.png', './porf_data/dtu/scan24/image/000028.png', './porf_data/dtu/scan24/image/000029.png', './porf_data/dtu/scan24/image/000030.png', './porf_data/dtu/scan24/image/000031.png', './porf_data/dtu/scan24/image/000032.png', './porf_data/dtu/scan24/image/000033.png', './porf_data/dtu/scan24/image/000034.png', './porf_data/dtu/scan24/image/000035.png', './porf_data/dtu/scan24/image/000036.png', './porf_data/dtu/scan24/image/000037.png', './porf_data/dtu/scan24/image/000038.png', './porf_data/dtu/scan24/image/000039.png', './porf_data/dtu/scan24/image/000040.png', './porf_data/dtu/scan24/image/000041.png', './porf_data/dtu/scan24/image/000042.png', './porf_data/dtu/scan24/image/000043.png', './porf_data/dtu/scan24/image/000044.png', './porf_data/dtu/scan24/image/000045.png', './porf_data/dtu/scan24/image/000046.png', './porf_data/dtu/scan24/image/000047.png', './porf_data/dtu/scan24/image/000048.png']
C:\Users\krameri120\Desktop\porf\models\dataset.py:100: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  self.intrinsics_all = torch.stack(self.intrinsics_all).to(self.device)   # [n_images, 4, 4]
(49, 1200, 1600, 3)
Load data: End
sdf network dims: [39, 256, 256, 256, 256, 256, 256, 256, 256, 257]
D:\anaconda3\envs\porf\lib\site-packages\torch\nn\utils\weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
init_r range:  [tensor(-1.8556), tensor(0.9810)]
init_t range:  [tensor(-1.6791), tensor(1.5757)]
  2%|▏         | 999/50000 [09:02<7:47:42,  1.75it/s]./exp_dtu/scan24/dtu_sift_porf
iter:1000 loss = 0.3608134090900421 lr=0.0009997618131650427
  4%|▍         | 1999/50000 [14:45<3:14:41,  4.11it/s]./exp_dtu/scan24/dtu_sift_porf
iter:2000 loss = 0.33677566051483154 lr=0.0009978520278860464
  6%|▌         | 2999/50000 [23:13<3:10:11,  4.12it/s]./exp_dtu/scan24/dtu_sift_porf
iter:3000 loss = 0.2766687572002411 lr=0.0009940382343809299
  8%|▊         | 3999/50000 [27:19<3:12:54,  3.97it/s]./exp_dtu/scan24/dtu_sift_porf
iter:4000 loss = 0.27543073892593384 lr=0.0009883357894500833
 10%|▉         | 4999/50000 [31:25<2:59:40,  4.17it/s]./exp_dtu/scan24/dtu_sift_porf
iter:5000 loss = 0.2872655689716339 lr=0.0009807676548266012
 12%|█▏        | 5999/50000 [35:28<3:09:18,  3.87it/s]./exp_dtu/scan24/dtu_sift_porf
iter:6000 loss = 0.21646320819854736 lr=0.0009713643047174859
 14%|█▍        | 6999/50000 [39:32<2:55:42,  4.08it/s]./exp_dtu/scan24/dtu_sift_porf
iter:7000 loss = 0.21613185107707977 lr=0.0009601636030947734
 16%|█▌        | 7999/50000 [43:40<2:52:33,  4.06it/s]./exp_dtu/scan24/dtu_sift_porf
iter:8000 loss = 0.26595282554626465 lr=0.0009472106512306805
 18%|█▊        | 8999/50000 [47:44<2:50:56,  4.00it/s]./exp_dtu/scan24/dtu_sift_porf
iter:9000 loss = 0.2479216754436493 lr=0.0009325576060906999
 20%|█▉        | 9999/50000 [51:49<2:45:48,  4.02it/s]./exp_dtu/scan24/dtu_sift_porf
iter:10000 loss = 0.2655978202819824 lr=0.0009162634703159097
 22%|██▏       | 10999/50000 [55:57<2:37:50,  4.12it/s]./exp_dtu/scan24/dtu_sift_porf
iter:11000 loss = 0.26702043414115906 lr=0.000898393854640161
 24%|██▍       | 11999/50000 [1:00:02<2:37:54,  4.01it/s]./exp_dtu/scan24/dtu_sift_porf
iter:12000 loss = 0.16443629562854767 lr=0.0008790207136988108
 26%|██▌       | 12999/50000 [1:04:05<2:32:19,  4.05it/s]./exp_dtu/scan24/dtu_sift_porf
iter:13000 loss = 0.2216898500919342 lr=0.0008582220562928003
 28%|██▊       | 13999/50000 [1:08:07<2:23:58,  4.17it/s]./exp_dtu/scan24/dtu_sift_porf
iter:14000 loss = 0.14629040658473969 lr=0.000836081631274747
 30%|██▉       | 14999/50000 [1:12:09<2:20:36,  4.15it/s]./exp_dtu/scan24/dtu_sift_porf
iter:15000 loss = 0.17617455124855042 lr=0.0008126885903218738
 32%|███▏      | 15999/50000 [1:16:12<2:13:53,  4.23it/s]./exp_dtu/scan24/dtu_sift_porf
iter:16000 loss = 0.20443782210350037 lr=0.0007881371289536697
 34%|███▍      | 16999/50000 [1:20:14<2:09:42,  4.24it/s]./exp_dtu/scan24/dtu_sift_porf
iter:17000 loss = 0.20663928985595703 lr=0.0007625261072397793
 36%|███▌      | 17999/50000 [1:24:16<2:13:24,  4.00it/s]./exp_dtu/scan24/dtu_sift_porf
iter:18000 loss = 0.22240164875984192 lr=0.0007359586517253936
 38%|███▊      | 18999/50000 [1:28:19<2:02:39,  4.21it/s]./exp_dtu/scan24/dtu_sift_porf
iter:19000 loss = 0.231417715549469 lr=0.0007085417401770513
 40%|███▉      | 19999/50000 [1:32:25<2:02:25,  4.08it/s]./exp_dtu/scan24/dtu_sift_porf
iter:20000 loss = 0.22961357235908508 lr=0.0006803857708209296
 42%|████▏     | 20999/50000 [1:36:33<1:51:53,  4.32it/s]./exp_dtu/scan24/dtu_sift_porf
iter:21000 loss = 0.22914618253707886 lr=0.0006516041178081515
 44%|████▍     | 21999/50000 [1:40:36<1:51:45,  4.18it/s]./exp_dtu/scan24/dtu_sift_porf
iter:22000 loss = 0.18078012764453888 lr=0.0006223126746970946
 46%|████▌     | 22999/50000 [1:44:42<1:50:29,  4.07it/s]./exp_dtu/scan24/dtu_sift_porf
iter:23000 loss = 0.19000928103923798 lr=0.0005926293877909347
 48%|████▊     | 23999/50000 [1:48:48<1:49:20,  3.96it/s]./exp_dtu/scan24/dtu_sift_porf
iter:24000 loss = 0.24345944821834564 lr=0.0005626737812095115
 50%|████▉     | 24999/50000 [1:52:53<1:41:08,  4.12it/s]./exp_dtu/scan24/dtu_sift_porf
iter:25000 loss = 0.19834363460540771 lr=0.000532566475607884
 52%|█████▏    | 25999/50000 [1:56:57<1:35:46,  4.18it/s]./exp_dtu/scan24/dtu_sift_porf
iter:26000 loss = 0.16089364886283875 lr=0.000502428702479524
 54%|█████▍    | 26999/50000 [2:01:04<1:34:26,  4.06it/s]./exp_dtu/scan24/dtu_sift_porf
iter:27000 loss = 0.153246209025383 lr=0.0004723818159998801
 56%|█████▌    | 27999/50000 [2:05:09<1:28:46,  4.13it/s]./exp_dtu/scan24/dtu_sift_porf
iter:28000 loss = 0.15105146169662476 lr=0.0004425468043759446
 58%|█████▊    | 28999/50000 [2:09:16<1:24:57,  4.12it/s]./exp_dtu/scan24/dtu_sift_porf
iter:29000 loss = 0.1820262372493744 lr=0.00041304380266944543
 60%|█████▉    | 29999/50000 [2:13:19<1:20:54,  4.12it/s]./exp_dtu/scan24/dtu_sift_porf
iter:30000 loss = 0.14901556074619293 lr=0.0003839916090553543
 62%|██████▏   | 30999/50000 [2:17:22<1:15:34,  4.19it/s]./exp_dtu/scan24/dtu_sift_porf
iter:31000 loss = 0.17078541219234467 lr=0.0003555072064635643
 64%|██████▍   | 31999/50000 [2:21:25<1:11:24,  4.20it/s]./exp_dtu/scan24/dtu_sift_porf
iter:32000 loss = 0.21702301502227783 lr=0.00032770529152992023
 66%|██████▌   | 32999/50000 [2:25:28<1:08:28,  4.14it/s]./exp_dtu/scan24/dtu_sift_porf
iter:33000 loss = 0.15694203972816467 lr=0.00030069781275334704
 68%|██████▊   | 33999/50000 [2:34:12<3:30:03,  1.27it/s]./exp_dtu/scan24/dtu_sift_porf
iter:34000 loss = 0.19447582960128784 lr=0.00027459351971875713
 70%|██████▉   | 34999/50000 [2:45:26<3:02:12,  1.37it/s]./exp_dtu/scan24/dtu_sift_porf
iter:35000 loss = 0.14895427227020264 lr=0.00024949752520085253
 72%|███████▏  | 35999/50000 [2:56:47<2:21:59,  1.64it/s]./exp_dtu/scan24/dtu_sift_porf
iter:36000 loss = 0.13709375262260437 lr=0.00022551088191208248
 74%|███████▍  | 36999/50000 [3:07:47<2:55:15,  1.24it/s]./exp_dtu/scan24/dtu_sift_porf
iter:37000 loss = 0.17597171664237976 lr=0.0002027301755990345
 76%|███████▌  | 37999/50000 [3:15:52<49:06,  4.07it/s]./exp_dtu/scan24/dtu_sift_porf
iter:38000 loss = 0.17233240604400635 lr=0.0001812471361257229
 78%|███████▊  | 38999/50000 [3:19:59<44:46,  4.10it/s]./exp_dtu/scan24/dtu_sift_porf
iter:39000 loss = 0.13661247491836548 lr=0.0001611482681098015
 80%|███████▉  | 39999/50000 [3:24:07<39:41,  4.20it/s]./exp_dtu/scan24/dtu_sift_porf
iter:40000 loss = 0.1881733536720276 lr=0.0001425145025990004
 82%|████████▏ | 40999/50000 [3:28:15<36:24,  4.12it/s]./exp_dtu/scan24/dtu_sift_porf
iter:41000 loss = 0.19745075702667236 lr=0.00012542087119036028
 84%|████████▍ | 41999/50000 [3:32:19<32:24,  4.11it/s]./exp_dtu/scan24/dtu_sift_porf
iter:42000 loss = 0.15781797468662262 lr=0.00010993620390447295
 86%|████████▌ | 42999/50000 [3:36:27<27:30,  4.24it/s]./exp_dtu/scan24/dtu_sift_porf
iter:43000 loss = 0.20856142044067383 lr=9.612285203128168e-05
 88%|████████▊ | 43999/50000 [3:40:35<24:22,  4.10it/s]./exp_dtu/scan24/dtu_sift_porf
iter:44000 loss = 0.1952916979789734 lr=8.403643706344363e-05
 90%|████████▉ | 44999/50000 [3:44:42<20:23,  4.09it/s]./exp_dtu/scan24/dtu_sift_porf
iter:45000 loss = 0.16854506731033325 lr=7.372562672820924e-05
 92%|█████████▏| 45999/50000 [3:48:49<15:58,  4.17it/s]./exp_dtu/scan24/dtu_sift_porf
iter:46000 loss = 0.1697336882352829 lr=6.523193901966224e-05
 94%|█████████▍| 46999/50000 [3:53:03<12:13,  4.09it/s]./exp_dtu/scan24/dtu_sift_porf
iter:47000 loss = 0.18469974398612976 lr=5.858957502041093e-05
 96%|█████████▌| 47999/50000 [3:57:09<08:07,  4.10it/s]./exp_dtu/scan24/dtu_sift_porf
iter:48000 loss = 0.1668275147676468 lr=5.382528118589918e-05
 98%|█████████▊| 48999/50000 [4:01:14<04:05,  4.08it/s]./exp_dtu/scan24/dtu_sift_porf
iter:49000 loss = 0.1461760699748993 lr=5.0958241645870776e-05
100%|█████████▉| 49999/50000 [4:05:23<00:00,  3.95it/s]./exp_dtu/scan24/dtu_sift_porf
iter:50000 loss = 0.14655056595802307 lr=5.0000000956649774e-05
100%|██████████| 50000/50000 [4:05:23<00:00,  3.40it/s]
threshold: 0.0
D:\anaconda3\envs\porf\lib\site-packages\torch\functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\TensorShape.cpp:3610.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[export.py:78 -          export_mesh() ] Exporting 1072785 faces as PLY
[export.py:78 -          export_mesh() ] Exporting 1072779 faces as PLY
[export.py:78 -          export_mesh() ] Exporting 1072779 faces as PLY
[export.py:78 -          export_mesh() ] Exporting 1072779 faces as PLY
[export.py:78 -          export_mesh() ] Exporting 1072785 faces as PLY
[train.py:454 -        validate_mesh() ] End
Validate: iter: 50000, camera: 32
